{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import csv\n",
    "import string\n",
    "import pickle\n",
    "from sentistrength import PySentiStr\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0    0\n",
      "Review        0\n",
      "UpVotes       0\n",
      "Rating        0\n",
      "Label         0\n",
      "Length        0\n",
      "Positive      0\n",
      "Negative      0\n",
      "Present       0\n",
      "Past          0\n",
      "Future        0\n",
      "b             0\n",
      "f             0\n",
      "r             0\n",
      "u             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dataset_new = pd.read_csv('dataset_new.csv')\n",
    "dataset = dataset_new\n",
    "\n",
    "missing_values_check = dataset.isnull().sum()\n",
    "print(missing_values_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b', 'f', 'r', 'u']\n"
     ]
    }
   ],
   "source": [
    "categories = list(dataset.columns.values)\n",
    "categories = categories[11:]\n",
    "print(categories)\n",
    "# b for bug_reports, f for feature_requests, r for ratings, u for user_experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  category  number of reviews\n",
      "0        b                783\n",
      "1        f                218\n",
      "2        r                260\n",
      "3        u                752\n"
     ]
    }
   ],
   "source": [
    "counts = []\n",
    "for category in categories:\n",
    "    counts.append((category, dataset[category].sum()))\n",
    "df_stats = pd.DataFrame(counts, columns=['category', 'number of reviews'])\n",
    "print(df_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(dataset, test_size=0.25, random_state=13, shuffle=True)\n",
    "train_text = train['Review'].values.astype('U')\n",
    "test_text = test['Review'].values.astype('U')\n",
    "\n",
    "vectorizer = TfidfVectorizer(strip_accents='unicode', analyzer='word', ngram_range=(1,3), max_features=15000)\n",
    "vectorizer.fit(train_text)\n",
    "vectorizer.fit(test_text)\n",
    "pickle.dump(vectorizer, open(\"vectorizer.pickle\", \"wb\"))\n",
    "print(len(vectorizer.get_feature_names()))\n",
    "\n",
    "x_train = vectorizer.transform(train_text)\n",
    "y_train = train.drop(labels=['Unnamed: 0', 'UpVotes', 'Rating', 'Label', 'Review', 'Length', 'Positive', 'Negative', 'Present', 'Past', 'Future'], axis=1)\n",
    "x_test = vectorizer.transform(test_text)\n",
    "y_test = test.drop(labels=['Unnamed: 0', 'UpVotes', 'Rating', 'Label', 'Review', 'Length', 'Positive', 'Negative', 'Present', 'Past', 'Future'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(1509, 15000)\n",
      "(1509, 4)\n",
      "(504, 15000)\n",
      "(504, 4)\n"
     ]
    }
   ],
   "source": [
    "print(type(x_train))\n",
    "print(type(y_train))\n",
    "print(type(x_test))\n",
    "print(type(y_test))\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-class classification (only BOW, excluding metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Binary Classifications - (One Vs Rest Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Processing b reviews...**\n",
      "Test accuracy is 0.7579365079365079\n",
      "\n",
      "\n",
      "**Processing f reviews...**\n",
      "Test accuracy is 0.8888888888888888\n",
      "\n",
      "\n",
      "**Processing r reviews...**\n",
      "Test accuracy is 0.8650793650793651\n",
      "\n",
      "\n",
      "**Processing u reviews...**\n",
      "Test accuracy is 0.6924603174603174\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using pipeline for applying logistic regression and one vs rest classifier\n",
    "LogReg_pipeline = Pipeline([\n",
    "                ('clf', OneVsRestClassifier(LogisticRegression(solver='sag', max_iter=10000), n_jobs=-1)),\n",
    "            ])\n",
    "\n",
    "for category in categories:\n",
    "    print('**Processing {} reviews...**'.format(category))\n",
    "    \n",
    "    # Training logistic regression model on train data\n",
    "    LogReg_pipeline.fit(x_train, train[category])\n",
    "    pickle.dump(LogReg_pipeline, open(\"classifier_\"+ str(category) +\".pickle\", \"wb\"))\n",
    "    # calculating test accuracy\n",
    "    prediction = LogReg_pipeline.predict(x_test)\n",
    "    print('Test accuracy is {}'.format(accuracy_score(test[category], prediction)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
